# Severity Assessment Testing

This component evaluates an automated severity assessment system for tool side effects in multi-agent environments using semantic similarity matching between tool descriptions and reference texts across five ordinal severity levels (very low to very high). The system employs embedding-based cosine similarity to classify 67 manually labeled tools from filesystem, GitHub, and web search categories, achieving a Spearman's rank correlation of 0.6520 (p < 0.0001) between predicted and ground truth severity scores. Ground truth labels were assigned based on reversibility, scope of impact, data integrity risks, and workflow disruption potential, with validation through consistency checks and logical ordering verification. The results demonstrate the system's effectiveness in automatically identifying tool risk levels, with consistent performance across read-only operations (very low severity) and destructive operations (very high severity), though some misclassification occurs at severity boundaries and for context-sensitive tools. 